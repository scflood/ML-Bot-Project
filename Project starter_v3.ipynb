{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import Levenshtein as Lev\n",
    "from sklearn.utils import shuffle\n",
    "import datetime as dt\n",
    "import editdistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203451 entries, 0 to 203450\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   user_id                203451 non-null  object\n",
      " 1   user_key               203451 non-null  object\n",
      " 2   created_at             203451 non-null  object\n",
      " 3   created_str            203451 non-null  object\n",
      " 4   retweet_count          203451 non-null  object\n",
      " 5   retweeted              203451 non-null  object\n",
      " 6   favorite_count         203451 non-null  object\n",
      " 7   text                   203451 non-null  object\n",
      " 8   tweet_id               203451 non-null  object\n",
      " 9   source                 203451 non-null  object\n",
      " 10  hashtags               203451 non-null  object\n",
      " 11  expanded_urls          203451 non-null  object\n",
      " 12  posted                 203451 non-null  object\n",
      " 13  mentions               203451 non-null  object\n",
      " 14  retweeted_status_id    203451 non-null  object\n",
      " 15  in_reply_to_status_id  203451 non-null  object\n",
      "dtypes: object(16)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#data from nbc release, not cresci\n",
    "rus_tweets = pd.read_csv('tweets.csv', na_filter=False)\n",
    "rus_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_rus_tweets = rus_tweets[0:10]\n",
    "samp_rus_tweets = samp_rus_tweets['text']\n",
    "samp_rus_tweets = samp_rus_tweets.str.replace(' ','')\n",
    "samp_rus_tweets = samp_rus_tweets.str.replace('RT@','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           #ThingsDoneByMistakekissingauntieinthelips\n",
       "1    mc_derpin:#TheOlderWeGetthemorepessimisticwear...\n",
       "2    dmataconis:ReadyToFeelLikeAFailure?JoanOfArcWa...\n",
       "3        Amen!#blacklivesmatterhttps://t.co/wGffaOqgzl\n",
       "4    NahBabyNah:Twitchy:ChuckToddcaughtoutthereshil...\n",
       "5    mcicero10:#BernieSanders#Trumppeopleshouldrall...\n",
       "6    ItsJustJaynie:@HillaryClintonTheundecidedvoter...\n",
       "7                               @TodayCleveland'noway'\n",
       "8    @NickTomaWBREHi,Nick!We'reholdinga\"MinersforTr...\n",
       "9       What.Is.A.Resolution#My4WordNewYearsResolution\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_rus_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "dist = np.empty(samp_rus_tweets.shape[0]**2, dtype=int)\n",
    "for i, x in enumerate(product(samp_rus_tweets, repeat=2)):\n",
    "     dist[i] = editdistance.eval(*x)\n",
    "dist_df = pd.DataFrame(dist.reshape(-1, samp_rus_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3    4    5    6    7    8    9\n",
      "0    0  59  85  41  102   85   78   35  103   40\n",
      "1   59   0  73  47   95   83   78   63   91   60\n",
      "2   85  73   0  80   90   95   88   89   92   84\n",
      "3   41  47  80   0   98   93   79   37   96   46\n",
      "4  102  95  90  98    0  106  103  107  100  105\n",
      "5   85  83  95  93  106    0   91   98   99   93\n",
      "6   78  78  88  79  103   91    0   82  103   80\n",
      "7   35  63  89  37  107   98   82    0  109   40\n",
      "8  103  91  92  96  100   99  103  109    0  105\n",
      "9   40  60  84  46  105   93   80   40  105    0\n"
     ]
    }
   ],
   "source": [
    "print(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.11999999999999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dist = dist_df.mean()\n",
    "mean_dist.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_user_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_tweets_sorted = rus_tweets.sort_values(by=['user_key'])\n",
    "rus_tweets_sorted = rus_tweets_sorted['text']\n",
    "rus_tweets_sorted = rus_tweets_sorted.str.replace(' ','')\n",
    "rus_tweets_sorted = rus_tweets_sorted.str.replace('RT@','')\n",
    "#sorted1 - sorted28 corresponds to user1 - user 28\n",
    "rus_tweets_sorted1 = rus_tweets_sorted[4171:4207]\n",
    "\n",
    "rus_tweets_sorted2 = rus_tweets_sorted[4208:4224]\n",
    "rus_tweets_sorted3 = rus_tweets_sorted[4225:4289]\n",
    "rus_tweets_sorted4 = rus_tweets_sorted[4290:4327]\n",
    "rus_tweets_sorted5 = rus_tweets_sorted[4328:4340]\n",
    "rus_tweets_sorted6 = rus_tweets_sorted[4341:4380]\n",
    "#rus_tweets_sorted7 = rus_tweets_sorted[4381:4381]\n",
    "rus_tweets_sorted8 = rus_tweets_sorted[4382:4432]\n",
    "rus_tweets_sorted9 = rus_tweets_sorted[4433:4434]\n",
    "rus_tweets_sorted10 = rus_tweets_sorted[4435:4487]\n",
    "rus_tweets_sorted11 = rus_tweets_sorted[4488:4892]\n",
    "rus_tweets_sorted12 = rus_tweets_sorted[4893:4908]\n",
    "rus_tweets_sorted13 = rus_tweets_sorted[4909:4932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_tweets_sorted14 = rus_tweets_sorted[4933:4941]\n",
    "rus_tweets_sorted15 = rus_tweets_sorted[4942:5015]\n",
    "rus_tweets_sorted16a = rus_tweets_sorted[5016:9284]\n",
    "rus_tweets_sorted16b = rus_tweets_sorted[9285:14284]\n",
    "#rus_tweets_sorted17 = rus_tweets_sorted[14285:14285]\n",
    "rus_tweets_sorted18 = rus_tweets_sorted[14286:14317]\n",
    "#rus_tweets_sorted19 = rus_tweets_sorted[14318:14318]\n",
    "rus_tweets_sorted20 = rus_tweets_sorted[14319:14469]\n",
    "rus_tweets_sorted21 = rus_tweets_sorted[14470:15814]\n",
    "rus_tweets_sorted22 = rus_tweets_sorted[15815:15899]\n",
    "rus_tweets_sorted23 = rus_tweets_sorted[15900:15902]\n",
    "rus_tweets_sorted24 = rus_tweets_sorted[15903:15939]\n",
    "#i think below is bad data\n",
    "#rus_tweets_sorted25 = rus_tweets_sorted[15940:15946]\n",
    "#rus_tweets_sorted26 = rus_tweets_sorted[15940:15946]\n",
    "#rus_tweets_sorted27 = rus_tweets_sorted[15940:15946]\n",
    "#rus_tweets_sorted28 = rus_tweets_sorted[15940:15946]\n",
    "rus_user_list.append(rus_tweets_sorted1)\n",
    "rus_user_list.append(rus_tweets_sorted2)\n",
    "rus_user_list.append(rus_tweets_sorted3)\n",
    "rus_user_list.append(rus_tweets_sorted4)\n",
    "rus_user_list.append(rus_tweets_sorted5)\n",
    "rus_user_list.append(rus_tweets_sorted6)\n",
    "rus_user_list.append(rus_tweets_sorted8)\n",
    "rus_user_list.append(rus_tweets_sorted9)\n",
    "rus_user_list.append(rus_tweets_sorted10)\n",
    "rus_user_list.append(rus_tweets_sorted11)\n",
    "rus_user_list.append(rus_tweets_sorted12)\n",
    "rus_user_list.append(rus_tweets_sorted13)\n",
    "rus_user_list.append(rus_tweets_sorted14)\n",
    "rus_user_list.append(rus_tweets_sorted15)\n",
    "rus_user_list.append(rus_tweets_sorted16a)\n",
    "rus_user_list.append(rus_tweets_sorted16b)\n",
    "rus_user_list.append(rus_tweets_sorted18)\n",
    "rus_user_list.append(rus_tweets_sorted20)\n",
    "rus_user_list.append(rus_tweets_sorted21)\n",
    "rus_user_list.append(rus_tweets_sorted22)\n",
    "rus_user_list.append(rus_tweets_sorted23)\n",
    "rus_user_list.append(rus_tweets_sorted24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.42438271604937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.empty(rus_tweets_sorted1.shape[0]**2, dtype=int)\n",
    "for i, x in enumerate(product(rus_tweets_sorted1, repeat=2)):\n",
    "     dist[i] = editdistance.eval(*x)\n",
    "dist_df = pd.DataFrame(dist.reshape(-1, rus_tweets_sorted1.shape[0]))\n",
    "mean_dist = dist_df.mean()\n",
    "mean_dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.03125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#page 32 has more data set info\n",
    "# find Lev distance for the user #2\n",
    "dist = np.empty(rus_tweets_sorted2.shape[0]**2, dtype=int)\n",
    "for i, x in enumerate(product(rus_tweets_sorted2, repeat=2)):\n",
    "     dist[i] = editdistance.eval(*x)\n",
    "dist_df = pd.DataFrame(dist.reshape(-1, rus_tweets_sorted2.shape[0]))\n",
    "mean_dist = dist_df.mean()\n",
    "mean_dist.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.empty(rus_tweets_sorted3.shape[0]**2, dtype=int)\n",
    "for i, x in enumerate(product(rus_tweets_sorted3, repeat=2)):\n",
    "     dist[i] = editdistance.eval(*x)\n",
    "dist_df = pd.DataFrame(dist.reshape(-1, rus_tweets_sorted3.shape[0]))\n",
    "mean_dist = dist_df.mean()\n",
    "mean_dist.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_edit_rus = []\n",
    "for user in rus_user_list:\n",
    "    dist = np.empty(user.shape[0]**2, dtype=int)\n",
    "    for i, x in enumerate(product(user, repeat=2)):\n",
    "         dist[i] = editdistance.eval(*x)\n",
    "    dist_df = pd.DataFrame(dist.reshape(-1, user.shape[0]))\n",
    "    mean_dist = dist_df.mean()\n",
    "    mean_edit_rus.append(mean_dist.mean())\n",
    "#print(mean_edit)\n",
    "# Lev for 16\n",
    "#(98.90660460926716 + 99.0721426541758)/2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (0,3,5,6,8,12,13,14,18,19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2839362 entries, 0 to 2839361\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Dtype \n",
      "---  ------                   ----- \n",
      " 0   id                       object\n",
      " 1   text                     object\n",
      " 2   source                   object\n",
      " 3   user_id                  object\n",
      " 4   truncated                object\n",
      " 5   in_reply_to_status_id    object\n",
      " 6   in_reply_to_user_id      object\n",
      " 7   in_reply_to_screen_name  object\n",
      " 8   retweeted_status_id      object\n",
      " 9   geo                      object\n",
      " 10  place                    object\n",
      " 11  contributors             object\n",
      " 12  retweet_count            object\n",
      " 13  reply_count              object\n",
      " 14  favorite_count           object\n",
      " 15  favorited                object\n",
      " 16  retweeted                object\n",
      " 17  possibly_sensitive       object\n",
      " 18  num_hashtags             object\n",
      " 19  num_urls                 object\n",
      " 20  num_mentions             object\n",
      " 21  created_at               object\n",
      " 22  timestamp                object\n",
      " 23  crawled_at               object\n",
      " 24  updated                  object\n",
      "dtypes: object(25)\n",
      "memory usage: 541.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Real Tweets Data Set\n",
    "real_tweets = pd.read_csv('datasets_full.csv/genuine_accounts.csv/tweets.csv', na_filter=False)\n",
    "real_tweets['user_id'] = real_tweets['user_id'].str.replace(' ','')\n",
    "real_tweets.fillna('')\n",
    "real_tweets.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_tweets['user_id'] = real_tweets['user_id'].astype(str).astype(int)\n",
    "# real_tweets['user_id'].tail()\n",
    "#real_tweets.info()\n",
    "real_tweets_sorted = real_tweets.sort_values(by=['user_id'])\n",
    "real_tweets_sorted = real_tweets_sorted['text']\n",
    "real_tweets_sorted = real_tweets_sorted.str.replace(' ','')\n",
    "real_tweets_sorted = real_tweets_sorted.str.replace('RT@','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839361                                                     \n",
       "2818997                          Ellenhttp://t.co/ZUUCv9mYgZ\n",
       "2818995                       Bigcut.https://t.co/7hw5mfrt2Y\n",
       "2818993    WhywouldDereklookphoneandthenatruckhithim?Just...\n",
       "2818992                                         @DempeoMDMer\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_tweets_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_tweets_sorted1 = real_tweets_sorted[981668:982560]\n",
    "real_tweets_sorted2 = real_tweets_sorted[982561:985677]\n",
    "real_tweets_sorted3 = real_tweets_sorted[985678:988132]\n",
    "real_tweets_sorted4 = real_tweets_sorted[988133:991368]\n",
    "real_tweets_sorted5 = real_tweets_sorted[991369:994578]\n",
    "real_tweets_sorted6 = real_tweets_sorted[994579:997773]\n",
    "real_tweets_sorted7 = real_tweets_sorted[997774:1000994]\n",
    "real_tweets_sorted8 = real_tweets_sorted[1000995:1004171]\n",
    "real_tweets_sorted9 = real_tweets_sorted[1004172:1007390]\n",
    "real_tweets_sorted10 = real_tweets_sorted[1007391:1010510]\n",
    "real_tweets_sorted11 = real_tweets_sorted[1010511:1013599]\n",
    "real_tweets_sorted12 = real_tweets_sorted[1013600:1013941]\n",
    "real_tweets_sorted13 = real_tweets_sorted[1013942:1017137]\n",
    "real_tweets_sorted14 = real_tweets_sorted[1017138:1019436]\n",
    "real_tweets_sorted15 = real_tweets_sorted[1019437:1022622]\n",
    "real_tweets_sorted16 = real_tweets_sorted[1022623:1025845]\n",
    "real_tweets_sorted17 = real_tweets_sorted[1025846:1029038]\n",
    "real_tweets_sorted18 = real_tweets_sorted[1029039:1032277]\n",
    "real_tweets_sorted19 = real_tweets_sorted[1032278:1035441]\n",
    "real_tweets_sorted20 = real_tweets_sorted[1035442:1036606]\n",
    "real_tweets_sorted21 = real_tweets_sorted[1036607:1039781]\n",
    "real_tweets_sorted22 = real_tweets_sorted[1039782:1042953]\n",
    "real_tweets_sorted23 = real_tweets_sorted[1042954:1045336]\n",
    "real_tweets_sorted24 = real_tweets_sorted[1045337:1045417]\n",
    "real_tweets_sorted25 = real_tweets_sorted[1045418:1048574]\n",
    "real_user_list = []\n",
    "# import copy\n",
    "# for real_user in range(1, 26):\n",
    "#     name = \"real_tweets_sorted\"+str(real_user)\n",
    "#     print(name)\n",
    "#     real_user_list.append(copy.deepcopy(name))\n",
    "# print(real_user_list[1])\n",
    "real_user_list.append(real_tweets_sorted1)\n",
    "real_user_list.append(real_tweets_sorted2)\n",
    "real_user_list.append(real_tweets_sorted3)\n",
    "real_user_list.append(real_tweets_sorted4)\n",
    "real_user_list.append(real_tweets_sorted5)\n",
    "real_user_list.append(real_tweets_sorted6)\n",
    "real_user_list.append(real_tweets_sorted7)\n",
    "real_user_list.append(real_tweets_sorted8)\n",
    "real_user_list.append(real_tweets_sorted9)\n",
    "real_user_list.append(real_tweets_sorted10)\n",
    "real_user_list.append(real_tweets_sorted11)\n",
    "real_user_list.append(real_tweets_sorted12)\n",
    "real_user_list.append(real_tweets_sorted13)\n",
    "real_user_list.append(real_tweets_sorted14)\n",
    "real_user_list.append(real_tweets_sorted15)\n",
    "real_user_list.append(real_tweets_sorted16)\n",
    "real_user_list.append(real_tweets_sorted17)\n",
    "real_user_list.append(real_tweets_sorted18)\n",
    "real_user_list.append(real_tweets_sorted19)\n",
    "real_user_list.append(real_tweets_sorted20)\n",
    "real_user_list.append(real_tweets_sorted21)\n",
    "real_user_list.append(real_tweets_sorted22)\n",
    "real_user_list.append(real_tweets_sorted23)\n",
    "real_user_list.append(real_tweets_sorted24)\n",
    "real_user_list.append(real_tweets_sorted25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_edit_real = []\n",
    "for real_user in real_user_list:    \n",
    "    dist = np.empty(real_user.shape[0]**2, dtype=int)\n",
    "    for i, x in enumerate(product(real_user, repeat=2)):\n",
    "        dist[i] = editdistance.eval(*x)\n",
    "    dist_df = pd.DataFrame(dist.reshape(-1, real_user.shape[0]))\n",
    "    mean_dist = dist_df.mean()\n",
    "    mean_edit_real.append(mean_dist.mean())\n",
    "    #stopped at in[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crowdflower_results.csv',\n",
       " 'crowdflower_results.csv.zip',\n",
       " 'fake_followers.csv',\n",
       " 'fake_followers.csv.zip',\n",
       " 'genuine_accounts.csv',\n",
       " 'genuine_accounts.csv.zip',\n",
       " 'READ.ME',\n",
       " 'social_spambots_1.csv',\n",
       " 'social_spambots_1.csv.zip',\n",
       " 'social_spambots_2.csv',\n",
       " 'social_spambots_2.csv.zip',\n",
       " 'social_spambots_3.csv',\n",
       " 'social_spambots_3.csv.zip',\n",
       " 'traditional_spambots_1.csv',\n",
       " 'traditional_spambots_1.csv.zip',\n",
       " 'traditional_spambots_2.csv',\n",
       " 'traditional_spambots_2.csv.zip',\n",
       " 'traditional_spambots_3.csv',\n",
       " 'traditional_spambots_3.csv.zip',\n",
       " 'traditional_spambots_4.csv',\n",
       " 'traditional_spambots_4.csv.zip',\n",
       " '__MACOSX']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"datasets_full.csv/\")\n",
    "os.getcwd()\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3474 entries, 0 to 3473\n",
      "Data columns (total 42 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   id                                  3474 non-null   int64 \n",
      " 1   name                                3474 non-null   object\n",
      " 2   screen_name                         3474 non-null   object\n",
      " 3   statuses_count                      3474 non-null   int64 \n",
      " 4   followers_count                     3474 non-null   int64 \n",
      " 5   friends_count                       3474 non-null   int64 \n",
      " 6   favourites_count                    3474 non-null   int64 \n",
      " 7   listed_count                        3474 non-null   int64 \n",
      " 8   url                                 3474 non-null   object\n",
      " 9   lang                                3474 non-null   object\n",
      " 10  time_zone                           3474 non-null   object\n",
      " 11  location                            3474 non-null   object\n",
      " 12  default_profile                     3474 non-null   object\n",
      " 13  default_profile_image               3474 non-null   object\n",
      " 14  geo_enabled                         3474 non-null   object\n",
      " 15  profile_image_url                   3474 non-null   object\n",
      " 16  profile_banner_url                  3474 non-null   object\n",
      " 17  profile_use_background_image        3474 non-null   object\n",
      " 18  profile_background_image_url_https  3474 non-null   object\n",
      " 19  profile_text_color                  3474 non-null   object\n",
      " 20  profile_image_url_https             3474 non-null   object\n",
      " 21  profile_sidebar_border_color        3474 non-null   object\n",
      " 22  profile_background_tile             3474 non-null   object\n",
      " 23  profile_sidebar_fill_color          3474 non-null   object\n",
      " 24  profile_background_image_url        3474 non-null   object\n",
      " 25  profile_background_color            3474 non-null   object\n",
      " 26  profile_link_color                  3474 non-null   object\n",
      " 27  utc_offset                          3474 non-null   object\n",
      " 28  is_translator                       3474 non-null   object\n",
      " 29  follow_request_sent                 3474 non-null   object\n",
      " 30  protected                           3474 non-null   object\n",
      " 31  verified                            3474 non-null   object\n",
      " 32  notifications                       3474 non-null   object\n",
      " 33  description                         3474 non-null   object\n",
      " 34  contributors_enabled                3474 non-null   object\n",
      " 35  following                           3474 non-null   object\n",
      " 36  created_at                          3474 non-null   object\n",
      " 37  timestamp                           3474 non-null   object\n",
      " 38  crawled_at                          3474 non-null   object\n",
      " 39  updated                             3474 non-null   object\n",
      " 40  test_set_1                          3474 non-null   int64 \n",
      " 41  test_set_2                          3474 non-null   int64 \n",
      "dtypes: int64(8), object(34)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# need genuine accounts for support vector machining\n",
    "real = pd.read_csv('genuine_accounts.csv/users.csv')\n",
    "real = real.fillna('')\n",
    "real.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>notifications</th>\n",
       "      <th>description</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>following</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "      <th>test_set_1</th>\n",
       "      <th>test_set_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>3156622237</td>\n",
       "      <td>RoboDerp</td>\n",
       "      <td>RoboDerp</td>\n",
       "      <td>19061</td>\n",
       "      <td>243</td>\n",
       "      <td>241</td>\n",
       "      <td>487</td>\n",
       "      <td>22</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>I am just a dumb robot. Do not engage. I repea...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tue Apr 14 15:17:36 +0000 2015</td>\n",
       "      <td>2015-04-14 17:17:36</td>\n",
       "      <td>2015-05-02 01:57:33</td>\n",
       "      <td>2016-03-15 15:59:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>3158349782</td>\n",
       "      <td>OSU Ladder</td>\n",
       "      <td>osuladder</td>\n",
       "      <td>96</td>\n",
       "      <td>158</td>\n",
       "      <td>179</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>I'm just a small town ladder living above the ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Thu Apr 16 00:45:01 +0000 2015</td>\n",
       "      <td>2015-04-16 02:45:01</td>\n",
       "      <td>2015-05-02 01:57:39</td>\n",
       "      <td>2016-03-15 16:08:35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>3159993463</td>\n",
       "      <td>martin lee</td>\n",
       "      <td>WriterMJLee</td>\n",
       "      <td>107</td>\n",
       "      <td>146</td>\n",
       "      <td>336</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Creative Director. Writer. Wine Drinker. Pick ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Thu Apr 16 16:09:47 +0000 2015</td>\n",
       "      <td>2015-04-16 18:09:47</td>\n",
       "      <td>2015-05-02 01:57:51</td>\n",
       "      <td>2016-03-15 16:01:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>3161171948</td>\n",
       "      <td>丸董</td>\n",
       "      <td>otto395</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>zh-tw</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fri Apr 17 14:08:13 +0000 2015</td>\n",
       "      <td>2015-04-17 16:08:13</td>\n",
       "      <td>2015-05-02 01:57:52</td>\n",
       "      <td>2016-03-15 16:08:35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3164941860</td>\n",
       "      <td>Ariana Reweti</td>\n",
       "      <td>ArianaReweti</td>\n",
       "      <td>133</td>\n",
       "      <td>72</td>\n",
       "      <td>460</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mon Apr 20 07:28:31 +0000 2015</td>\n",
       "      <td>2015-04-20 09:28:31</td>\n",
       "      <td>2015-05-02 01:57:58</td>\n",
       "      <td>2016-03-15 15:54:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id           name   screen_name  statuses_count  \\\n",
       "1228  3156622237       RoboDerp      RoboDerp           19061   \n",
       "2924  3158349782     OSU Ladder     osuladder              96   \n",
       "1552  3159993463     martin lee   WriterMJLee             107   \n",
       "2926  3161171948             丸董       otto395               6   \n",
       "134   3164941860  Ariana Reweti  ArianaReweti             133   \n",
       "\n",
       "      followers_count  friends_count  favourites_count  listed_count url  \\\n",
       "1228              243            241               487            22       \n",
       "2924              158            179                39             0       \n",
       "1552              146            336                24             1       \n",
       "2926                3             11                 0             0       \n",
       "134                72            460               146             0       \n",
       "\n",
       "       lang  ... notifications  \\\n",
       "1228     en  ...                 \n",
       "2924     en  ...                 \n",
       "1552     en  ...                 \n",
       "2926  zh-tw  ...                 \n",
       "134      en  ...                 \n",
       "\n",
       "                                            description contributors_enabled  \\\n",
       "1228  I am just a dumb robot. Do not engage. I repea...                        \n",
       "2924  I'm just a small town ladder living above the ...                        \n",
       "1552  Creative Director. Writer. Wine Drinker. Pick ...                        \n",
       "2926                                                                           \n",
       "134                                                                            \n",
       "\n",
       "     following                      created_at            timestamp  \\\n",
       "1228            Tue Apr 14 15:17:36 +0000 2015  2015-04-14 17:17:36   \n",
       "2924            Thu Apr 16 00:45:01 +0000 2015  2015-04-16 02:45:01   \n",
       "1552            Thu Apr 16 16:09:47 +0000 2015  2015-04-16 18:09:47   \n",
       "2926            Fri Apr 17 14:08:13 +0000 2015  2015-04-17 16:08:13   \n",
       "134             Mon Apr 20 07:28:31 +0000 2015  2015-04-20 09:28:31   \n",
       "\n",
       "               crawled_at              updated test_set_1 test_set_2  \n",
       "1228  2015-05-02 01:57:33  2016-03-15 15:59:58          1          0  \n",
       "2924  2015-05-02 01:57:39  2016-03-15 16:08:35          1          0  \n",
       "1552  2015-05-02 01:57:51  2016-03-15 16:01:35          0          0  \n",
       "2926  2015-05-02 01:57:52  2016-03-15 16:08:35          1          0  \n",
       "134   2015-05-02 01:57:58  2016-03-15 15:54:28          0          0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = real.sort_values(by=['id'])\n",
    "real.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428542 entries, 0 to 428541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   id                       428542 non-null  int64 \n",
      " 1   text                     428542 non-null  object\n",
      " 2   source                   428542 non-null  object\n",
      " 3   user_id                  428542 non-null  int64 \n",
      " 4   truncated                428542 non-null  object\n",
      " 5   in_reply_to_status_id    428542 non-null  int64 \n",
      " 6   in_reply_to_user_id      428542 non-null  int64 \n",
      " 7   in_reply_to_screen_name  428542 non-null  object\n",
      " 8   retweeted_status_id      428542 non-null  int64 \n",
      " 9   geo                      428542 non-null  object\n",
      " 10  place                    428542 non-null  object\n",
      " 11  contributors             428542 non-null  object\n",
      " 12  retweet_count            428542 non-null  int64 \n",
      " 13  reply_count              428542 non-null  int64 \n",
      " 14  favorite_count           428542 non-null  int64 \n",
      " 15  favorited                428542 non-null  object\n",
      " 16  retweeted                428542 non-null  object\n",
      " 17  possibly_sensitive       428542 non-null  object\n",
      " 18  num_hashtags             428542 non-null  int64 \n",
      " 19  num_urls                 428542 non-null  int64 \n",
      " 20  num_mentions             428542 non-null  int64 \n",
      " 21  created_at               428542 non-null  object\n",
      " 22  timestamp                428542 non-null  object\n",
      " 23  crawled_at               428542 non-null  object\n",
      " 24  updated                  428542 non-null  object\n",
      "dtypes: int64(11), object(14)\n",
      "memory usage: 81.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('social_spambots_2.csv/tweets.csv')\n",
    "df = df.fillna('')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('social_spambots_2.csv/tweets.csv')\n",
    "df = df.fillna('')\n",
    "#df['default_profile'].isnull().values.sum()\n",
    "# need genuine accounts for support vector machining\n",
    "real = pd.read_csv('genuine_accounts.csv/tweets.csv')\n",
    "real = real.fillna('')\n",
    "# temp. subset for testing SVM\n",
    "# real = real[1:1000]\n",
    "# fake followers\n",
    "fake_followers = pd.read_csv('fake_followers.csv/tweets.csv')\n",
    "fake_followers.fillna('')\n",
    "# traditional spambots\n",
    "trad_spam_1 = pd.read_csv('social_spambots_1.csv/tweets.csv')\n",
    "trad_spam_1 = trad_spam_1.fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# social spambots\n",
    "social_spam_1 = pd.read_csv('social_spambots_1.csv/tweets.csv')\n",
    "social_spam_1 = social_spam_1.fillna('')\n",
    "social_spam_2 = pd.read_csv('social_spambots_2.csv/tweets.csv')\n",
    "social_spam_2 = social_spam_2.fillna('')\n",
    "social_spam_3 = pd.read_csv('social_spambots_3.csv/tweets.csv')\n",
    "social_spam_3 = social_spam_3.fillna('')\n",
    "rus_tweets.fillna('')\n",
    "rus_tweets = rus_tweets.replace(np.nan, '', regex=True)\n",
    "# column detailing if they are a bot\n",
    "# will be deleted later for SVM\n",
    "real['knownbot'] = 0\n",
    "df['knownbot'] = 1\n",
    "fake_followers['knownbot'] = 1\n",
    "trad_spam_1['knownbot'] = 1\n",
    "social_spam_1['knownbot'] = 1\n",
    "social_spam_2['knownbot'] = 1\n",
    "social_spam_3['knownbot'] = 1\n",
    "rus_tweets['knownbot'] = 1\n",
    "#len(real['default_profile'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframe. append dataframes.\n",
    "# combine all social spambots\n",
    "#all_trad_spam = pd.concat([trad_spam_1,trad_spam_2,trad_spam_3])\n",
    "#all_social_spambots = pd.concat([social_spam_1,social_spam_2,social_spam_3])\n",
    "#all_bots = pd.concat([all_social_spambots,fake_followers])\n",
    "# df = pd.concat([df,real])\n",
    "#df = pd.concat([real, rus_users])\n",
    "#len(df['default_profile'])\n",
    "df = shuffle(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Average number of Tweets\n",
    "# ss1 = social_spam_1['num_hashtags'].mean()\n",
    "# ss2 = social_spam_2['num_hashtags'].mean()\n",
    "# ss3 = social_spam_3['num_hashtags'].mean()\n",
    "# ts1 = trad_spam_1['num_hashtags'].mean()\n",
    "# #ts2 = trad_spam_2['num_hashtags'].mean()\n",
    "# #ts3 = trad_spam_3['num_hashtags'].mean()\n",
    "# r1 = real['num_hashtags'].mean()\n",
    "# f1 = fake_followers['num_hashtags'].mean()\n",
    "# #rus1 = rus_tweets['num_hashtags'].mean()\n",
    "# sets = [ss1,ss2,ss3,ts1,ts2,ts3,r1,f1]\n",
    "# # xlabel = ('Social 1', 'Social 2', 'Social 3', 'Traditional 1', 'Real Accounts', 'Fake\n",
    "Followers', 'Russian Bots')\n",
    "# xlabel = ('Social 1', 'Social 2', 'Social 3', 'Traditional 1', 'Real Accounts', 'Fake\n",
    "Followers')\n",
    "# ypos = np.arange(len(sets))\n",
    "# amount = [ss1,ss2,ss3,ts1,r1,f1]\n",
    "# plt.bar(xlabel, sets, align='center', alpha=0.5)\n",
    "# plt.xticks(ypos,xlabel,rotation=30)\n",
    "# plt.ylabel('Average Number of Favorites')\n",
    "# plt.title('Average Number of Favorites Per Account Per Dataset')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert timestamp to datetime format\n",
    "# # month/day/year hour:minute:second AM\n",
    "# df['timestamp'] = df['timestamp'].apply(lambda x:\n",
    "dt.datetime.strptime(x,'%b%d%Y:%H:%M:%S.%f'))\n",
    "# # df['Mycol'] = df['Mycol'].apply(lambda x:\n",
    "dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create empty DF and add id\n",
    "# score = pd.DataFrame()\n",
    "# score['id'] = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function that will be used for scoring\n",
    "# # is language english\n",
    "# def scoring (row):\n",
    "# if row['lang'] == 'en':\n",
    "# return 1\n",
    "# else:\n",
    "# return 0\n",
    "\n",
    "# # function is applied\n",
    "# df.apply (lambda row: scoring (row),axis=1)\n",
    "# #output of function applied to rows is assigned to df collumn\n",
    "# df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# # no null values in new score collumn (this collumn could be part of a new df)\n",
    "# df['score'].isnull().values.sum()\n",
    "# # assigns function output to new df\n",
    "# score['lang-en'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# coding: utf-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import Levenshtein as Lev\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.utils import shuffle\n",
    "import datetime as dt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russian Data Set\n",
    "rus_users = pd.read_csv('users.csv',\n",
    "na_filter=False)\n",
    "rus_users.fillna('')\n",
    "#rus_users.rename(columns={})\n",
    "#rus_users['knownbot'] = 1\n",
    "#list(rus_users)\n",
    "rus_users[['id','followers_count','statuses_count','favourites_count','friends_count']] =\n",
    "rus_users[['id','followers_count','statuses_count','favourites_count','friends_count']].ap\n",
    "ply(pd.to_numeric)\n",
    "rus_users['id'] = rus_users['id'].fillna(0).astype(int)\n",
    "rus_users['followers_count'] = rus_users['followers_count'].fillna(0).astype(int)\n",
    "rus_users['statuses_count'] = rus_users['statuses_count'].fillna(0).astype(int)\n",
    "rus_users['favourites_count'] = rus_users['favourites_count'].fillna(0).astype(int)\n",
    "rus_users['friends_count'] = rus_users['friends_count'].fillna(0).astype(int)\n",
    "#rus_users = rus_users.replace(np.nan, '', regex=True)\n",
    "#rus_users[('followers_count','statuses_count','favourites_count','friends_count')].appl\n",
    "ymap(int)\n",
    "rus_users.fillna('')\n",
    "#rus_users = rus_users.replace(np.nan, '', regex=True)\n",
    "#int(rus_users['followers_count'])\n",
    "#rus_users.shape\n",
    "rus_users.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"datasets_full.csv/\")\n",
    "os.getcwd()\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('social_spambots_1.csv/users.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df.ix[:5,:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default_profile'].isnull().values.sum()\n",
    "len(df['default_profile'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need genuine accounts for support vector machining\n",
    "real = pd.read_csv('genuine_accounts.csv/users.csv')\n",
    "real = real.fillna('')\n",
    "# temp. subset for testing SVM\n",
    "# real = real[1:1000]\n",
    "# fake followers\n",
    "fake_followers = pd.read_csv('fake_followers.csv/users.csv')\n",
    "fake_followers.fillna('')\n",
    "# traditional spambots\n",
    "trad_spam_1 = pd.read_csv('traditional_spambots_1.csv/users.csv')\n",
    "trad_spam_2 = pd.read_csv('traditional_spambots_2.csv/users.csv')\n",
    "trad_spam_3 = pd.read_csv('traditional_spambots_3.csv/users.csv')\n",
    "#trad_spam_4 = pd.read_csv('social_spambots_4.csv/users.csv')\n",
    "trad_spam_1 = trad_spam_1.fillna('')\n",
    "trad_spam_2 = trad_spam_2.fillna('')\n",
    "trad_spam_3 = trad_spam_3.fillna('')\n",
    "#trad_spam_4 = trad_spam_4.fillna('')\n",
    "# social spambots\n",
    "social_spam_1 = pd.read_csv('social_spambots_1.csv/users.csv')\n",
    "social_spam_1 = social_spam_1.fillna('')\n",
    "social_spam_2 = pd.read_csv('social_spambots_2.csv/users.csv')\n",
    "social_spam_2 = social_spam_2.fillna('')\n",
    "social_spam_3 = pd.read_csv('social_spambots_3.csv/users.csv')\n",
    "social_spam_3 = social_spam_3.fillna('')\n",
    "rus_users.fillna('')\n",
    "rus_users = rus_users.replace(np.nan, '', regex=True)\n",
    "# column detailing if they are a bot\n",
    "# will be deleted later for SVM\n",
    "real['knownbot'] = 0\n",
    "df['knownbot'] = 1\n",
    "fake_followers['knownbot'] = 1\n",
    "trad_spam_1['knownbot'] = 1\n",
    "trad_spam_2['knownbot'] = 1\n",
    "trad_spam_3['knownbot'] = 1\n",
    "#trad_spam_4['knownbot'] = 1\n",
    "social_spam_1['knownbot'] = 1\n",
    "social_spam_2['knownbot'] = 1\n",
    "social_spam_3['knownbot'] = 1\n",
    "rus_users['knownbot'] = 1\n",
    "len(real['default_profile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Twitter Accounts Per Dataset\n",
    "ss1 = len(social_spam_1)\n",
    "ss2 = len(social_spam_2)\n",
    "ss3 = len(social_spam_3)\n",
    "ts1 = len(trad_spam_1)\n",
    "ts2 = len(trad_spam_2)\n",
    "ts3 = len(trad_spam_3)\n",
    "r1 = len(real)\n",
    "f1 = len(fake_followers)\n",
    "rus1 = len(rus_users)\n",
    "# # Average number of followers\n",
    "# ss1 = social_spam_1['followers_count'].mean()\n",
    "# ss2 = social_spam_2['followers_count'].mean()\n",
    "# ss3 = social_spam_3['followers_count'].mean()\n",
    "# ts1 = trad_spam_1['followers_count'].mean()\n",
    "# ts2 = trad_spam_2['followers_count'].mean()\n",
    "# ts3 = trad_spam_3['followers_count'].mean()\n",
    "# r1 = real['followers_count'].mean()\n",
    "# f1 = fake_followers['followers_count'].mean()\n",
    "# rus1 = rus_users['followers_count'].mean()\n",
    "# # Average number of friends\n",
    "# ss1 = social_spam_1['friends_count'].mean()\n",
    "# ss2 = social_spam_2['friends_count'].mean()\n",
    "# ss3 = social_spam_3['friends_count'].mean()\n",
    "# ts1 = trad_spam_1['friends_count'].mean()\n",
    "# ts2 = trad_spam_2['friends_count'].mean()\n",
    "# ts3 = trad_spam_3['friends_count'].mean()\n",
    "# r1 = real['friends_count'].mean()\n",
    "# f1 = fake_followers['friends_count'].mean()\n",
    "# rus1 = rus_users['friends_count'].mean()\n",
    "# # Average number of Tweets\n",
    "# ss1 = social_spam_1['statuses_count'].mean()\n",
    "# ss2 = social_spam_2['statuses_count'].mean()\n",
    "# ss3 = social_spam_3['statuses_count'].mean()\n",
    "# ts1 = trad_spam_1['statuses_count'].mean()\n",
    "# ts2 = trad_spam_2['statuses_count'].mean()\n",
    "# ts3 = trad_spam_3['statuses_count'].mean()\n",
    "# r1 = real['statuses_count'].mean()\n",
    "# f1 = fake_followers['statuses_count'].mean()\n",
    "# rus1 = rus_users['statuses_count'].mean()\n",
    "# # Average number of Favorites Per Dataset\n",
    "# ss1 = social_spam_1['favourites_count'].mean()\n",
    "# ss2 = social_spam_2['favourites_count'].mean()\n",
    "# ss3 = social_spam_3['favourites_count'].mean()\n",
    "# ts1 = trad_spam_1['favourites_count'].mean()\n",
    "# ts2 = trad_spam_2['favourites_count'].mean()\n",
    "# ts3 = trad_spam_3['favourites_count'].mean()\n",
    "# r1 = real['favourites_count'].mean()\n",
    "# f1 = fake_followers['favourites_count'].mean()\n",
    "# rus1 = rus_users['favourites_count'].mean()\n",
    "sets = [ss1,ss2,ss3,ts1,ts2,ts3,r1,f1,rus1]\n",
    "xlabel = ('Social 1', 'Social 2', 'Social 3', 'Traditional 1', 'Traditional 2', 'Traditional 3',\n",
    "'Real Accounts', 'Fake Followers', 'Russian Bots')\n",
    "ypos = np.arange(len(sets))\n",
    "amount = [ss1,ss2,ss3,ts1,ts2,ts3,r1,f1,rus1]\n",
    "plt.bar(xlabel, sets, align='center', alpha=0.5)\n",
    "plt.xticks(ypos,xlabel,rotation=30)\n",
    "# plt.ylabel('Average Number of Followers')\n",
    "# plt.title('Average Number of Followers Per Account Per Dataset')\n",
    "plt.ylabel('Number of Twitter Accounts')\n",
    "plt.title(' Number of Twitter Accounts Per Dataset')\n",
    "plt.show()\n",
    "print(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframe. append dataframes.\n",
    "# combine all social spambots\n",
    "all_trad_spam = pd.concat([trad_spam_1,trad_spam_2,trad_spam_3])\n",
    "all_social_spambots = pd.concat([social_spam_1,social_spam_2,social_spam_3])\n",
    "all_bots = pd.concat([all_trad_spam,all_social_spambots,fake_followers])\n",
    "# df = pd.concat([df,real])\n",
    "df = pd.concat([real, all_bots])\n",
    "len(df['default_profile'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare of Levenshtein Distance\n",
    "LevD_Rus =\n",
    "[87.22685185185186,75.6484375,93.87158203125,95.54127100073046,84.86111111\n",
    "11111,88.12097304404995,85.50719999999995,0.0,93.0051775147929,92.93727330\n",
    "653853,92.25777777777778,87.29300567107751,78.875,88.66128729592792,98.989\n",
    "37363172149,85.52549427679502,88.27911111111112,92.20204768105165,94.7046\n",
    "4852607702,34.5,87.5246913580247,76.22222222222223]\n",
    "LevD_Real =\n",
    "[65.56188793259464,68.06269743639605,80.99069695768078,35.81521735079752,\n",
    "41.59524071487558,54.80695468844404,69.17062343273791,77.40079028640484,6\n",
    "7.02438312151091,69.26917965276283,55.803792341740724,59.65946285291664,7\n",
    "0.02652325009018,74.53508708143696,82.96344570432927,72.94090538318754,75\n",
    ".49669423401855,86.23952096036828,59.65265730087915,57.51488084694314,56.\n",
    "52436582043217,59.63556497551856,77.69237444844183,87.1303125,81.64039747\n",
    "253511]\n",
    "# sort real dataset\n",
    "real = real.sort_values(by=['screen_name'])\n",
    "real_Lev = real.tail(25)\n",
    "real_Lev['LevD'] = LevD_Real\n",
    "# sort Russian bots dataset\n",
    "rus_users = rus_users.sort_values(by=['screen_name'])\n",
    "rus_users_Lev = rus_users.iloc[3:28]\n",
    "rus_users_Lev = rus_users_Lev.drop(rus_users_Lev.index[18])\n",
    "rus_users_Lev = rus_users_Lev.drop(rus_users_Lev.index[16])\n",
    "rus_users_Lev = rus_users_Lev.drop(rus_users_Lev.index[6])\n",
    "rus_users_Lev['LevD'] = LevD_Rus\n",
    "df = pd.concat([real_Lev, rus_users_Lev])\n",
    "real_Lev['LevD'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will be used for scoring\n",
    "# is language english\n",
    "def scoring (row):\n",
    "    if row['lang'] == 'en':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty DF and add id\n",
    "score = pd.DataFrame()\n",
    "score['id'] = df['id']\n",
    "# assigns function output to new df\n",
    "score['lang-en'] = df.apply (lambda row: scoring (row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has profile image.\n",
    "# change from using profile_banner_url\n",
    "def scoring (row):\n",
    "    if row['profile_image_url'] == '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['profile_pic'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['profile_pic'].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has screen name.\n",
    "# change from screen_name to name. screen_name = @handle. name: can be\n",
    "changed, not required.\n",
    "def scoring (row):\n",
    "    if row['name'] == '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['has_screen_name'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['has_screen_name'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has 30 followers\n",
    "def scoring (row):\n",
    "    if row['followers_count'] < 30:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['30followers'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['30followers'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring (row):\n",
    "    if row['geo_enabled'] == '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['geoloc'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['geoloc'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile banner contains a link ('http') from profile_banner_url\n",
    "# change to if the description contains\n",
    "def scoring (row):\n",
    "    if row['profile_banner_url'] == '':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# def scoring (row):\n",
    "# if 'http' not in row['description']:\n",
    "# return 0\n",
    "# elif row['description'] == '':\n",
    "# return 1\n",
    "# else:\n",
    "# return 1\n",
    "# df['description'] = df['description']\n",
    "# def scoring (row):\n",
    "# if row['description'] == ('http'):\n",
    "# return 0\n",
    "# else:\n",
    "# return 1\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['banner_link'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['banner_link'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has done 50 tweets\n",
    "def scoring (row):\n",
    "    if row['statuses_count'] > 50:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['50tweets'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['50tweets'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2* num followers >= # of friends\n",
    "def scoring (row):\n",
    "    if 2*row['followers_count'] >= row['friends_count']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['twice_num_followers'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['twice_num_followers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not have 1000s of friends, spambot\n",
    "def scoring (row):\n",
    "    if row['friends_count'] > 1000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['1000friends'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['1000friends'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent less than 20 tweets, spambot\n",
    "def scoring (row):\n",
    "    if row['statuses_count'] < 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['1000friends'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['1000friends'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# egg avatar, default profile image\n",
    "def scoring (row):\n",
    "    if row['default_profile_image'] == '':\n",
    "        return 0\n",
    "    else:\n",
    "         return 1\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['profile_pic'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['profile_pic'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Never tweeted\n",
    "def scoring (row):\n",
    "    if row['statuses_count'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['NeverTweeted'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['NeverTweeted'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50:1 friends/followers\n",
    "def scoring (row):\n",
    "    if 50*row['followers_count'] <= row['friends_count']:\n",
    "        return 1\n",
    "    else:\n",
    "         return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['fifty_FriendsFollowersRatio'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['fifty_FriendsFollowersRatio'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100:1 friends/followers\n",
    "def scoring (row):\n",
    "    if 100*row['followers_count'] <= row['friends_count']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['hundred_FriendsFollowersRatio'] = df.apply (lambda row: scoring\n",
    "(row),axis=1)\n",
    "score['hundred_FriendsFollowersRatio'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning of next draft...\n",
    "# profile contains a description\n",
    "def scoring (row):\n",
    "    if row['description'] == '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['has_description'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['has_description'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring (row):\n",
    "    if row['knownbot'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['knownbot'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['knownbot'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance less than 30\n",
    "def scoring (row):\n",
    "    if row['LevD'] < 30:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# function is applied\n",
    "df.apply (lambda row: scoring (row),axis=1)\n",
    "#output of function applied to rows is assigned to df collumn\n",
    "df['score'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "# no null values in new score collumn (this collumn could be part of a new df)\n",
    "df['score'].isnull().values.sum()\n",
    "# assigns function output to new df\n",
    "score['Levenshtein'] = df.apply (lambda row: scoring (row),axis=1)\n",
    "score['Levenshtein'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is based from Eric Larson code for his Data Mining Class\n",
    "#\n",
    "#https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and\n",
    "#%20SVM.ipynb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'knownbot' in score:\n",
    "    y = score['knownbot'].values # get the labels we want\n",
    "    del score['knownbot'] # get rid of the class label\n",
    "    X = score.values # use everything else to predict!\n",
    " ## X and y are now numpy matrices, by calling 'values' on the pandas data\n",
    "#frames we\n",
    " # have converted them into simple matrices to use with scikit learn\n",
    "\n",
    "\n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into\n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    " test_size = 0.2)\n",
    "print(cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "# first we create a reusable logisitic regression object\n",
    "# here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "# now we can use the cv_object that we setup before to iterate through the\n",
    "# different training and testing sets. Each time we will reuse the logisitic\n",
    "#regression\n",
    "# object, but it gets trained on different data each time we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y):\n",
    " # I will create new variables here so that it is more obvious what\n",
    " # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    " # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    " # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train) # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    " # now let's get the accuracy and confusion matrix for this iterations of\n",
    "#training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "\n",
    "# Also note that every time you run the above code\n",
    "# it randomly creates a new training and testing set,\n",
    "# so accuracy will be different each time\n",
    "# Also note that every time you run the above code\n",
    "# it randomly creates a new training and testing set,\n",
    "# so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret the weights\n",
    "# iterate over the coefficients\n",
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = score.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "\n",
    "# does this look correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# we want to normalize the features based upon the mean and standard deviation of\n",
    "#each column.\n",
    "# However, we do not want to accidentally use the testing data to find out the mean\n",
    "#and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the\n",
    "#variables:\n",
    "## X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit\n",
    "std\n",
    "# the line of code above only looks at training data to get mean and std and we can\n",
    "#use it\n",
    "# to transform new feature data\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set\n",
    "#(without snooping at the test set values)\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less\n",
    "#(can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train) # train object\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,score.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.style.use('ggplot')\n",
    "weights = pd.Series(lr_clf.coef_[0],index=score.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# we want to normalize the features based upon the mean and standard deviation of\n",
    "#each column.\n",
    "# However, we do not want to accidentally use the testing data to find out the mean\n",
    "#and std (this would be snooping)\n",
    "from sklearn.pipeline import Pipeline\n",
    "# you can apply the StandardScaler function inside of the cross-validation loop\n",
    "# but this requires the use of PipeLines in scikit.\n",
    "# A pipeline can apply feature pre-processing and data fitting in one compact\n",
    "#notation\n",
    "# Here is an example!\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05)\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl), # do this\n",
    " ('logit_model', lr_clf)]) # and then do this\n",
    "weights = []\n",
    "# run the pipline cross validated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    piped_object.fit(X[train_indices],y[train_indices]) # train object\n",
    " # it is a little odd getting trained objects from a pipeline:\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "error_y=dict(\n",
    " type='data',\n",
    " array=np.std(weights,axis=0),\n",
    " visible=True\n",
    " )\n",
    "graph1 = {'x': score.columns,\n",
    " 'y': np.mean(weights,axis=0),\n",
    " 'error_y':error_y,\n",
    " 'type': 'bar'}\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not sure if needed so haven't fixed yet\n",
    "# Xnew = df_imputed[['Age','Pclass','IsMale']].values\n",
    "# weights = []\n",
    "# # run the pipline corssvalidated\n",
    "# for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(Xnew,y)):\n",
    "# piped_object.fit(Xnew[train_indices],y[train_indices]) # train object\n",
    "# weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "\n",
    "# weights = np.array(weights)\n",
    "# error_y=dict(\n",
    "# type='data',\n",
    "# array=np.std(weights,axis=0),\n",
    "# visible=True\n",
    "# )\n",
    "# graph1 = {'x': ['Age','Pclass','IsMale'],\n",
    "# 'y': np.mean(weights,axis=0),\n",
    "# 'error_y':error_y,\n",
    "# 'type': 'bar'}\n",
    "# fig = dict()\n",
    "# fig['data'] = [graph1]\n",
    "# fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "# plotly.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, so run through the cross validation loop and set the training and testing\n",
    "#variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y):\n",
    " # I will create new variables here so that it is more obvious what\n",
    " # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    " # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train) # train object\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Without logistic regression\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X, y) # train object\n",
    "y_hat = svm_clf.predict(X) # get test set precitions\n",
    "acc = mt.accuracy_score(y,y_hat)\n",
    "conf = mt.confusion_matrix(y,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using linear kernel, these make sense to look at (not otherwise, why?)\n",
    "print(svm_clf.coef_)\n",
    "weights = pd.Series(svm_clf.coef_[0],index=df_imputed.columns)\n",
    "weights.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do some different analysis with the SVM and look at the instances that\n",
    "#were chosen as support vectors\n",
    "# now lets look at the support for the vectors and see if we they are indicative of\n",
    "#anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that\n",
    "#are hard to classify)\n",
    "# make a dataframe of the training data\n",
    "score_tested_on = score.iloc[train_indices] # saved from above, the indices chosen for\n",
    "#training\n",
    "# now get the support vectors from the trained model\n",
    "score_support = score_tested_on.iloc[svm_clf.support_,:]\n",
    "score_support['knownbot'] = y[svm_clf.support_] # add back in the 'Survived'\n",
    "#Column to the pandas dataframe\n",
    "score['knownbot'] = y # also add it back in for the original data\n",
    "score_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.tools.plotting import boxplot\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = score_support.groupby(['knownbot'])\n",
    "df_grouped = score.groupby(['knownbot'])\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['banner_link','profile_pic','has_screen_name','30followers']\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    " # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde()\n",
    "    plt.legend(['real','bot'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "\n",
    " # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde()\n",
    "    plt.legend(['real','bot'])\n",
    "    plt.title(v+' (Original)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lev.distance('Phillip Efthimion', '@RTscott_payne: Phillip Efthimion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('social_spambots_2.csv/tweets.csv')\n",
    "tweets = tweets.fillna('')\n",
    "tweets['text'] = tweets['text'].astype(str)\n",
    "tweets.info()\n",
    "rus_users['followers_count'] = rus_users['followers_count'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = tweets['text'][3:20]\n",
    "process.extract(tweets['text'][2], choices, limit=2)\n",
    "#process.extractOne(tweets['text'][1], choices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
